hadoop@ubu:~/Downloads$ hadoop jar wordcnt.jar my_driver /mydata/data.txt /mydata/output1
2025-04-20 19:59:11,218 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-04-20 19:59:11,385 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-04-20 19:59:11,389 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2025-04-20 19:59:11,577 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2025-04-20 19:59:11,754 INFO input.FileInputFormat: Total input files to process : 1
2025-04-20 19:59:11,897 INFO mapreduce.JobSubmitter: number of splits:1
2025-04-20 19:59:12,045 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2134862800_0001
2025-04-20 19:59:12,045 INFO mapreduce.JobSubmitter: Executing with tokens: []
2025-04-20 19:59:12,305 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2025-04-20 19:59:12,307 INFO mapreduce.Job: Running job: job_local2134862800_0001
2025-04-20 19:59:12,309 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2025-04-20 19:59:12,334 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory
2025-04-20 19:59:12,338 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2025-04-20 19:59:12,340 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-20 19:59:12,342 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2025-04-20 19:59:12,493 INFO mapred.LocalJobRunner: Waiting for map tasks
2025-04-20 19:59:12,501 INFO mapred.LocalJobRunner: Starting task: attempt_local2134862800_0001_m_000000_0
2025-04-20 19:59:12,613 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory
2025-04-20 19:59:12,613 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2025-04-20 19:59:12,613 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-20 19:59:12,673 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2025-04-20 19:59:12,698 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/mydata/data.txt:0+1362
2025-04-20 19:59:13,437 INFO mapreduce.Job: Job job_local2134862800_0001 running in uber mode : false
2025-04-20 19:59:13,438 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2025-04-20 19:59:13,441 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2025-04-20 19:59:13,441 INFO mapred.MapTask: soft limit at 83886080
2025-04-20 19:59:13,441 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2025-04-20 19:59:13,442 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2025-04-20 19:59:13,446 INFO mapreduce.Job:  map 0% reduce 0%
2025-04-20 19:59:13,454 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2025-04-20 19:59:13,992 INFO mapred.LocalJobRunner: 
2025-04-20 19:59:13,998 INFO mapred.MapTask: Starting flush of map output
2025-04-20 19:59:13,999 INFO mapred.MapTask: Spilling map output
2025-04-20 19:59:13,999 INFO mapred.MapTask: bufstart = 0; bufend = 2105; bufvoid = 104857600
2025-04-20 19:59:13,999 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213652(104854608); length = 745/6553600
2025-04-20 19:59:14,025 INFO mapred.MapTask: Finished spill 0
2025-04-20 19:59:14,121 INFO mapred.Task: Task:attempt_local2134862800_0001_m_000000_0 is done. And is in the process of committing
2025-04-20 19:59:14,130 INFO mapred.LocalJobRunner: map
2025-04-20 19:59:14,130 INFO mapred.Task: Task 'attempt_local2134862800_0001_m_000000_0' done.
2025-04-20 19:59:14,142 INFO mapred.Task: Final Counters for attempt_local2134862800_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=3997
		FILE: Number of bytes written=646972
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1362
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=11
		Map output records=187
		Map output bytes=2105
		Map output materialized bytes=2485
		Input split bytes=102
		Combine input records=0
		Spilled Records=187
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=439353344
	File Input Format Counters 
		Bytes Read=1362
2025-04-20 19:59:14,146 INFO mapred.LocalJobRunner: Finishing task: attempt_local2134862800_0001_m_000000_0
2025-04-20 19:59:14,150 INFO mapred.LocalJobRunner: map task executor complete.
2025-04-20 19:59:14,163 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2025-04-20 19:59:14,164 INFO mapred.LocalJobRunner: Starting task: attempt_local2134862800_0001_r_000000_0
2025-04-20 19:59:14,177 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory
2025-04-20 19:59:14,177 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2025-04-20 19:59:14,177 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-20 19:59:14,177 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2025-04-20 19:59:14,199 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@145f7d7d
2025-04-20 19:59:14,201 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2025-04-20 19:59:14,251 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=1620679040, maxSingleShuffleLimit=405169760, mergeThreshold=1069648192, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2025-04-20 19:59:14,282 INFO reduce.EventFetcher: attempt_local2134862800_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2025-04-20 19:59:14,343 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2134862800_0001_m_000000_0 decomp: 2481 len: 2485 to MEMORY
2025-04-20 19:59:14,348 INFO reduce.InMemoryMapOutput: Read 2481 bytes from map-output for attempt_local2134862800_0001_m_000000_0
2025-04-20 19:59:14,349 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2481, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2481
2025-04-20 19:59:14,356 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2025-04-20 19:59:14,358 INFO mapred.LocalJobRunner: 1 / 1 copied.
2025-04-20 19:59:14,364 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2025-04-20 19:59:14,396 INFO mapred.Merger: Merging 1 sorted segments
2025-04-20 19:59:14,398 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2473 bytes
2025-04-20 19:59:14,409 INFO reduce.MergeManagerImpl: Merged 1 segments, 2481 bytes to disk to satisfy reduce memory limit
2025-04-20 19:59:14,409 INFO reduce.MergeManagerImpl: Merging 1 files, 2485 bytes from disk
2025-04-20 19:59:14,410 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2025-04-20 19:59:14,410 INFO mapred.Merger: Merging 1 sorted segments
2025-04-20 19:59:14,418 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2473 bytes
2025-04-20 19:59:14,418 INFO mapred.LocalJobRunner: 1 / 1 copied.
2025-04-20 19:59:14,454 INFO mapreduce.Job:  map 100% reduce 0%
2025-04-20 19:59:14,528 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2025-04-20 19:59:15,190 INFO mapred.Task: Task:attempt_local2134862800_0001_r_000000_0 is done. And is in the process of committing
2025-04-20 19:59:15,204 INFO mapred.LocalJobRunner: 1 / 1 copied.
2025-04-20 19:59:15,206 INFO mapred.Task: Task attempt_local2134862800_0001_r_000000_0 is allowed to commit now
2025-04-20 19:59:15,293 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2134862800_0001_r_000000_0' to hdfs://localhost:9000/mydata/output1
2025-04-20 19:59:15,296 INFO mapred.LocalJobRunner: reduce > reduce
2025-04-20 19:59:15,296 INFO mapred.Task: Task 'attempt_local2134862800_0001_r_000000_0' done.
2025-04-20 19:59:15,297 INFO mapred.Task: Final Counters for attempt_local2134862800_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=8999
		FILE: Number of bytes written=649457
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1362
		HDFS: Number of bytes written=1324
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=129
		Reduce shuffle bytes=2485
		Reduce input records=187
		Reduce output records=129
		Spilled Records=187
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=439353344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=1324
2025-04-20 19:59:15,297 INFO mapred.LocalJobRunner: Finishing task: attempt_local2134862800_0001_r_000000_0
2025-04-20 19:59:15,297 INFO mapred.LocalJobRunner: reduce task executor complete.
2025-04-20 19:59:15,471 INFO mapreduce.Job:  map 100% reduce 100%
2025-04-20 19:59:15,471 INFO mapreduce.Job: Job job_local2134862800_0001 completed successfully
2025-04-20 19:59:15,502 INFO mapreduce.Job: Counters: 36
	File System Counters
		FILE: Number of bytes read=12996
		FILE: Number of bytes written=1296429
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2724
		HDFS: Number of bytes written=1324
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=11
		Map output records=187
		Map output bytes=2105
		Map output materialized bytes=2485
		Input split bytes=102
		Combine input records=0
		Combine output records=0
		Reduce input groups=129
		Reduce shuffle bytes=2485
		Reduce input records=187
		Reduce output records=129
		Spilled Records=374
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=878706688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1362
	File Output Format Counters 
		Bytes Written=1324
hadoop@ubu:~/Downloads$ hdfs dfs -cat /mydata/output1/*
(EDA)	1
(ML)	1
(mathematical	1
1959	1
Arthur	1
Data	1
From	1
History	1
IBM	1
ML	2
Machine	1
Samuel,	1
See	1
Statistics	1
The	3
Timeline	1
Within	1
a	6
advances	1
agriculture,	1
algorithms	1
algorithms,	1
allowed	1
also	1
also:	1
an	1
analysis	1
analytics.	1
and	7
application	2
approaches	1
approximately	1
artificial	2
as	1
business	1
by	1
can	1
class	1
coined	1
comprise	1
computer	2
computers	1
concerned	1
correct	1
data	2
data,	1
deep	1
describing	1
development	1
email	1
employee	1
explicit	1
exploratory	1
field	4
fields,	1
filtering,	1
finds	1
focusing	1
for	1
foundations	1
framework	1
from	1
gaming	1
generalize	1
have	1
in	8
including	1
instructions.[1]	1
intelligence	1
intelligence.[8][9]	1
is	3
known	1
language	1
learn	1
learning	6
learning,	1
learning.	2
learning.[6][7]	1
machine	6
many	2
mathematical	1
medicine.[3][4]	1
methods	1
mining	1
natural	1
networks,	1
neural	1
of	9
on	1
optimization	1
perform	1
performance.[2]	1
period.[10][11]	1
pioneer	1
predictive	1
previous	1
probably	1
problems	1
processing,	1
programming)	1
provides	1
recognition,	1
related	1
self-teaching	1
speech	1
statistical	2
study	2
study,	1
subdiscipline	1
surpass	1
synonym	1
tasks	1
term	1
that	1
the	4
theoretical	1
this	1
thus	1
time	1
to	3
unseen	1
unsupervised	1
used	1
via	1
viewpoint,	1
vision,	1
was	2
with	1
without	1

